#See the metrics.properties.template file inside spark/conf for documentation


#  syntax: [instance].sink|source.[name].[options]=[value]

# Enable ConsoleSink for all instances by class name
*.sink.console.class=org.apache.spark.metrics.sink.ConsoleSink

# Polling period for ConsoleSink
*.sink.console.period=1

*.sink.console.unit=seconds

# Master instance overlap polling period
#master.sink.console.period=15

#master.sink.console.unit=seconds

# You won't have a CSV sink unless you comment in this line
# The CSV files are currently set to go to your /tmp directory-- see below.
#*.sink.csv.class=org.apache.spark.metrics.sink.CsvSink

# Polling period for CsvSink
*.sink.csv.period=1

*.sink.csv.unit=seconds

# Polling directory for CsvSink
*.sink.csv.directory=/tmp/


# Enable jvm source for instance master, worker, driver and executor
#The Spark MetricsSystem find this property when a source we register has
#sourceName equal to the first name here ("custom"), or when the first name
#is "*". 
#Note that the Spark MetricsSystem loads this source by reflection.
#The JvmSource declares all its relevant counters. That is, no other 
#class needs a reference to the JvmSource in order to register metrics.
#This means that you probably don't want to register your custom
#source this way, since you'll want other classes to be able to 
#reference your sourcee; it holds a MetricsRegistry you'll need.
*.source.jvm.class=org.apache.spark.metrics.source.JvmSource

#worker.source.jvm.class=org.apache.spark.metrics.source.JvmSource

#driver.source.jvm.class=org.apache.spark.metrics.source.JvmSource

#executor.source.jvm.class=org.apache.spark.metrics.source.JvmSource


